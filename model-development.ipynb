{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluation Metrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning Model\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/antran/miniconda3/envs/healthcare-case-study/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/antran/miniconda3/envs/healthcare-case-study/lib/python3.11/site-packages (from xgboost) (1.14.1)\n",
      "Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "file_path = './data/Data Insights - Synthetic Dataset.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Data Insights - Synthetic Datas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert object columns to float\n",
    "def convert_to_float(df, columns):\n",
    "    for col in columns:\n",
    "        try:\n",
    "            # Attempt to convert the column to float\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            print(f\"Successfully converted {col} to float.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {col}: {e}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "charge_columns = ['AccommodationCharge', 'CCU_Charges', 'ICU_Charge', 'TheatreCharge', 'PharmacyCharge', 'ProsthesisCharge', 'OtherCharges', 'BundledCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted AccommodationCharge to float.\n",
      "Successfully converted CCU_Charges to float.\n",
      "Successfully converted ICU_Charge to float.\n",
      "Successfully converted TheatreCharge to float.\n",
      "Successfully converted PharmacyCharge to float.\n",
      "Successfully converted ProsthesisCharge to float.\n",
      "Successfully converted OtherCharges to float.\n",
      "Successfully converted BundledCharges to float.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = convert_to_float(df, charge_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in the charge columns with 0\n",
    "df[charge_columns] = df[charge_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Features from the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create Length of Stay Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Length of Stay (LOS)\n",
    "def calculate_length_of_stay(df, admission_col, separation_col):\n",
    "    # Convert admission and separation dates to datetime format\n",
    "    df[admission_col] = pd.to_datetime(df[admission_col], errors='coerce')\n",
    "    df[separation_col] = pd.to_datetime(df[separation_col], errors='coerce')\n",
    "    \n",
    "    # Calculate the difference in days between SeparationDate and AdmissionDate\n",
    "    df['LengthOfStay'] = (df[separation_col] - df[admission_col]).dt.days\n",
    "    \n",
    "    # Handle cases where LOS is negative or missing (e.g., errors in dates)\n",
    "    df['LengthOfStay'] = df['LengthOfStay'].apply(lambda x: x if x >= 0 else None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Applying the function\n",
    "df = calculate_length_of_stay(df, 'AdmissionDate', 'SeparationDate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create Total Charges Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Total Charge without PharmacyCharge\n",
    "df['TotalCharges'] = df[['AccommodationCharge', 'TheatreCharge', \n",
    "                         'ProsthesisCharge', 'OtherCharges', \n",
    "                         'BundledCharges', 'CCU_Charges', 'ICU_Charge']].sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.3 Map Diagnosis Codes to Categories\n",
    "# Define ICD-10 chapters with their corresponding code ranges\n",
    "icd10_chapters = [\n",
    "    ('A00', 'B99', 'Certain infectious and parasitic diseases'),\n",
    "    ('C00', 'D48', 'Neoplasms'),\n",
    "    ('D50', 'D89', 'Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism'),\n",
    "    ('E00', 'E89', 'Endocrine, nutritional and metabolic diseases'),\n",
    "    ('F00', 'F99', 'Mental and behavioural disorders'),\n",
    "    ('G00', 'G99', 'Diseases of the nervous system'),\n",
    "    ('H00', 'H59', 'Diseases of the eye and adnexa'),\n",
    "    ('H60', 'H95', 'Diseases of the ear and mastoid process'),\n",
    "    ('I00', 'I99', 'Diseases of the circulatory system'),\n",
    "    ('J00', 'J99', 'Diseases of the respiratory system'),\n",
    "    ('K00', 'K95', 'Diseases of the digestive system'),\n",
    "    ('L00', 'L99', 'Diseases of the skin and subcutaneous tissue'),\n",
    "    ('M00', 'M99', 'Diseases of the musculoskeletal system and connective tissue'),\n",
    "    ('N00', 'N99', 'Diseases of the genitourinary system'),\n",
    "    ('O00', 'O99', 'Pregnancy, childbirth and the puerperium'),\n",
    "    ('P00', 'P96', 'Certain conditions originating in the perinatal period'),\n",
    "    ('Q00', 'Q99', 'Congenital malformations, deformations and chromosomal abnormalities'),\n",
    "    ('R00', 'R99', 'Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified'),\n",
    "    ('S00', 'T98', 'Injury, poisoning and certain other consequences of external causes'),\n",
    "    ('U00', 'U99', 'Codes for special purposes'),\n",
    "    ('V00', 'Y99', 'External causes of morbidity and mortality'),\n",
    "    ('Z00', 'Z99', 'Factors influencing health status and contact with health services')\n",
    "]\n",
    "\n",
    "def map_icd10_to_chapter(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Maps an ICD-10 diagnosis code to its corresponding chapter.\n",
    "    \"\"\"\n",
    "    code = code.upper().strip()\n",
    "    if len(code) < 3:\n",
    "        code_prefix = code.ljust(3, '0')\n",
    "    else:\n",
    "        code_prefix = code[:3]\n",
    "    \n",
    "    for start, end, chapter in icd10_chapters:\n",
    "        if start <= code_prefix <= end:\n",
    "            return chapter\n",
    "    return 'Unknown'\n",
    "\n",
    "def add_icd10_chapters(df: pd.DataFrame, diagnosis_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds ICD-10 chapter mappings to the DataFrame for specified diagnosis columns.\n",
    "    \"\"\"\n",
    "    for diag_col in diagnosis_cols:\n",
    "        chapter_col = diag_col + '_Chapter'\n",
    "        df[chapter_col] = df[diag_col].apply(map_icd10_to_chapter)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ICD-10 Chapters\n",
    "df = add_icd10_chapters(df, ['PrincipalDiagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization (Optional)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(numerical_cols: list, categorical_cols: list) -> ColumnTransformer:\n",
    "    \"\"\"\n",
    "    Creates a ColumnTransformer for preprocessing numerical and categorical data.\n",
    "    \n",
    "    Parameters:\n",
    "    - numerical_cols (list): List of numerical column names.\n",
    "    - categorical_cols (list): List of categorical column names.\n",
    "    \n",
    "    Returns:\n",
    "    - preprocessor (ColumnTransformer): Preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    # Numerical preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Categorical preprocessing pipeline\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(preprocessor: ColumnTransformer, model_type: str = 'RandomForest') -> Pipeline:\n",
    "    \"\"\"\n",
    "    Creates a machine learning pipeline with preprocessing and regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    - preprocessor (ColumnTransformer): Preprocessing pipeline.\n",
    "    - model_type (str): Type of regression model ('RandomForest', 'GradientBoosting', 'LinearRegression').\n",
    "    \n",
    "    Returns:\n",
    "    - model (Pipeline): Complete machine learning pipeline.\n",
    "    \"\"\"\n",
    "    if model_type == 'RandomForest':\n",
    "        regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'GradientBoosting':\n",
    "        regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'LinearRegression':\n",
    "        regressor = LinearRegression()\n",
    "    elif model_type == 'XGBoost':\n",
    "        regressor = xgb.XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type. Choose from 'RandomForest', 'GradientBoosting', 'LinearRegression'.\")\n",
    "    \n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(model: Pipeline, X: pd.DataFrame, y: pd.Series, n_splits: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Performs cross-validation and returns evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (Pipeline): Machine learning pipeline.\n",
    "    - X (pd.DataFrame): Feature set.\n",
    "    - y (pd.Series): Target variable.\n",
    "    - n_splits (int): Number of cross-validation folds.\n",
    "    \n",
    "    Returns:\n",
    "    - cv_metrics (dict): Dictionary containing cross-validation metrics.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "    \n",
    "    cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    # Convert negative metrics to positive\n",
    "    cv_metrics = {\n",
    "        'Mean Absolute Error (MAE)': -cv_results['test_neg_mean_absolute_error'].mean(),\n",
    "        'Mean Squared Error (MSE)': -cv_results['test_neg_mean_squared_error'].mean(),\n",
    "        'R-squared (R²)': cv_results['test_r2'].mean()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nCross-Validation Metrics:\")\n",
    "    for metric, value in cv_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(model: Pipeline, X: pd.DataFrame, y: pd.Series, test_size: float = 0.2) -> (dict, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the data, trains the model, and evaluates it on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (Pipeline): Machine learning pipeline.\n",
    "    - X (pd.DataFrame): Feature set.\n",
    "    - y (pd.Series): Target variable.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    \n",
    "    Returns:\n",
    "    - test_metrics (dict): Dictionary containing test set evaluation metrics.\n",
    "    - y_pred (np.ndarray): Predicted values on the test set.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    test_metrics = {\n",
    "        'Mean Absolute Error (MAE)': mae,\n",
    "        'Root Mean Squared Error (RMSE)': rmse,\n",
    "        'R-squared (R²)': r2\n",
    "    }\n",
    "    \n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return test_metrics, y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthcare-case-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
